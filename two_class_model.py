# -*- coding: utf-8 -*-
"""Two Class Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fcnITAo5IybmnDFHRf2Dh32imvnFfGy-
"""

# Import library
import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Input

# Read and show data
df = pd.read_csv('https://drive.google.com/uc?id=1XZbZ5Z7MBXYaR3UO1HbQ4ncPi4R3HsyF')
df.head()

# Show info dataset
df.info()

# Change categorical data to numeric
label_encoder = preprocessing.LabelEncoder()
df['name'] = label_encoder.fit_transform(df['name'])
print(df)

df.info()

dataset = df.values

''' Select the last 5 columns as attributes
The number before the comma selects rows in the dataframe,
The number after the comma selects columns in the dataframe '''
X = dataset[:,1:6]

# Split the label from dataset
y = dataset[:,0]

# Create a MinMaxScaler object
min_max_scaler = preprocessing.MinMaxScaler()

# Fit the scaler to the data and transform it
X_scale = min_max_scaler.fit_transform(X)

# View the scaled data
X_scale

# Split the data to between training and testing
X_train, X_test, Y_train, Y_test = train_test_split(X_scale, y, test_size=0.3)

# Build a Sequential model for binary classification
model = Sequential([
    # Input layer: expect 5 features as input
    Input(shape=(5,)),

    # First hidden layer: 32 neurons, ReLU activation
    Dense(32, activation='relu'),

    # Second hidden layer: 32 neurons, ReLU activation
    Dense(32, activation='relu'),

    # Output layer: 1 neuron, sigmoid activation (for binary classification)
    Dense(1, activation='sigmoid')
])

# Use SGD (Stochastic Gradient Descent) and ‘binary_crossentropy’ as loss
model.compile(optimizer='sgd',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Start training
model.fit(X_train, Y_train, epochs=100)

# Evaluate the model
model.evaluate(X_test, Y_test, batch_size=1)